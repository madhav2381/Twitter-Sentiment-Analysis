{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter_Sentiment_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhav2381/Twitter-Sentiment-Analysis/blob/main/Twitter_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8wAuGmZ2lEs",
        "outputId": "04ae1baf-e05c-4b88-9acf-153fb57c1542"
      },
      "source": [
        "!pip install wordsegment\n",
        "!pip install autocorrect"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wordsegment\n",
            "  Downloading wordsegment-1.3.1-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.8 MB 24.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: wordsegment\n",
            "Successfully installed wordsegment-1.3.1\n",
            "Collecting autocorrect\n",
            "  Downloading autocorrect-2.6.0.tar.gz (622 kB)\n",
            "\u001b[K     |████████████████████████████████| 622 kB 22.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-2.6.0-py3-none-any.whl size=622249 sha256=097650a95360fa5104f52f3cf208d066dee885ee423c96a59cb4fa36db2a4af0\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/ce/aa/bc894efbe0541ce91dea21561d01d319783986d9787a8e9f58\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjwyZrrkaeyq"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import batch_normalization\n",
        "from keras.layers import Activation, Dense, Dropout, Dropout, Flatten, BatchNormalization, Input, Embedding, Bidirectional, LSTM\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras import utils\n",
        "from keras import backend as K\n",
        "from keras.models import *\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "import bs4\n",
        "import nltk\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from google.colab import files\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DPiclW_awXW",
        "outputId": "e050cbc0-12d8-44c8-b1a4-9fd45022404f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJawb9IWamHv",
        "outputId": "90e86834-18ee-4a36-8c0c-a5e5e090949b"
      },
      "source": [
        "!cp '/content/drive/MyDrive/training-Obama-Romney-tweets.rar' '/content'\n",
        "!unrar x 'training-Obama-Romney-tweets.rar'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from training-Obama-Romney-tweets.rar\n",
            "\n",
            "Extracting  training-Obama-Romney-tweets.xlsx                            \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXMAAAy2au3O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3550bea2-56d0-4f81-bf1d-5957d6908e50"
      },
      "source": [
        "data = pd.read_excel(\"/content/training-Obama-Romney-tweets.xlsx\", sheet_name = ['Obama', 'Romney'])\n",
        "data.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['Obama', 'Romney'])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJqHSUUDqatN"
      },
      "source": [
        "d1 = data['Obama']\n",
        "d2 = data['Romney']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "ImARKhKloXLP",
        "outputId": "fae145a3-0a0f-49c9-a4c7-c5f82343326b"
      },
      "source": [
        "d1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>date</th>\n",
              "      <th>time</th>\n",
              "      <th>Anootated tweet</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "      <th>Unnamed: 5</th>\n",
              "      <th>Unnamed: 6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1: positive, -1: negative, 0: neutral, 2: mixed</td>\n",
              "      <td>Class</td>\n",
              "      <td>Your class</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2012-10-16 00:00:00</td>\n",
              "      <td>10:28:53-05:00</td>\n",
              "      <td>Kirkpatrick, who wore a baseball cap embroider...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2016-12-10 00:00:00</td>\n",
              "      <td>10:09:00-05:00</td>\n",
              "      <td>Question: If &lt;e&gt;Romney&lt;/e&gt; and &lt;e&gt;Obama&lt;/e&gt; ha...</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2012-10-16 00:00:00</td>\n",
              "      <td>10:04:30-05:00</td>\n",
              "      <td>#&lt;e&gt;obama&lt;/e&gt; debates that Cracker Ass Cracker...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2012-10-16 00:00:00</td>\n",
              "      <td>10:00:36-05:00</td>\n",
              "      <td>RT @davewiner Slate: Blame &lt;e&gt;Obama&lt;/e&gt; for fo...</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                 date  ...  Unnamed: 5 Unnamed: 6\n",
              "0         NaN                  NaN  ...  Your class        NaN\n",
              "1         NaN  2012-10-16 00:00:00  ...         NaN        NaN\n",
              "2         NaN  2016-12-10 00:00:00  ...         NaN        NaN\n",
              "3         NaN  2012-10-16 00:00:00  ...         NaN        NaN\n",
              "4         NaN  2012-10-16 00:00:00  ...         NaN        NaN\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "rJlbwgNLuv1A",
        "outputId": "5a444753-3892-41b8-e8f2-3125ab4ad312"
      },
      "source": [
        "d2.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>date</th>\n",
              "      <th>time</th>\n",
              "      <th>Anootated tweet</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "      <th>Unnamed: 5</th>\n",
              "      <th>Unnamed: 6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1: positive, -1: negative, 0: neutral, 2: mixed</td>\n",
              "      <td>Class</td>\n",
              "      <td>Your class label</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2012-10-16 00:00:00</td>\n",
              "      <td>09:38:08-05:00</td>\n",
              "      <td>Insidious!&lt;e&gt;Mitt Romney&lt;/e&gt;'s Bain Helped Phi...</td>\n",
              "      <td>-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2012-10-16 00:00:00</td>\n",
              "      <td>10:22:34-05:00</td>\n",
              "      <td>Senior &lt;e&gt;Romney&lt;/e&gt; Advisor Claims &lt;e&gt;Obama&lt;/...</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2012-10-16 00:00:00</td>\n",
              "      <td>10:14:18-05:00</td>\n",
              "      <td>.@WardBrenda @shortwave8669 @allanbourdius you...</td>\n",
              "      <td>-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2012-10-16 00:00:00</td>\n",
              "      <td>09:27:16-05:00</td>\n",
              "      <td>&lt;e&gt;Mitt Romney&lt;/e&gt; still doesn't &lt;a&gt;believe&lt;/a...</td>\n",
              "      <td>-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                 date  ...        Unnamed: 5 Unnamed: 6\n",
              "0         NaN                  NaN  ...  Your class label        NaN\n",
              "1         NaN  2012-10-16 00:00:00  ...               NaN        NaN\n",
              "2         NaN  2012-10-16 00:00:00  ...               NaN        NaN\n",
              "3         NaN  2012-10-16 00:00:00  ...               NaN        NaN\n",
              "4         NaN  2012-10-16 00:00:00  ...               NaN        NaN\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2zB72Wmgo43"
      },
      "source": [
        "d1.drop(labels = ['Unnamed: 0', 'Unnamed: 5', 'Unnamed: 6', 'date','time'], axis=1, inplace=True)\n",
        "d2.drop(labels = ['Unnamed: 0', 'Unnamed: 5', 'Unnamed: 6','date','time'], axis=1, inplace=True)\n",
        "d1.drop(0, inplace=True)\n",
        "d2.drop(0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjogfT0Zm8yj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "54fc613f-211b-4aa1-8786-57edde159f91"
      },
      "source": [
        "train_data = d1.append(d2)\n",
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Anootated tweet</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Kirkpatrick, who wore a baseball cap embroider...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Question: If &lt;e&gt;Romney&lt;/e&gt; and &lt;e&gt;Obama&lt;/e&gt; ha...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#&lt;e&gt;obama&lt;/e&gt; debates that Cracker Ass Cracker...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @davewiner Slate: Blame &lt;e&gt;Obama&lt;/e&gt; for fo...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>@Hollivan @hereistheanswer  Youre missing the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     Anootated tweet Unnamed: 4\n",
              "1  Kirkpatrick, who wore a baseball cap embroider...          0\n",
              "2  Question: If <e>Romney</e> and <e>Obama</e> ha...          2\n",
              "3  #<e>obama</e> debates that Cracker Ass Cracker...          1\n",
              "4  RT @davewiner Slate: Blame <e>Obama</e> for fo...          2\n",
              "5  @Hollivan @hereistheanswer  Youre missing the ...          0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B95v0-1GjHUF"
      },
      "source": [
        "train_data.rename(columns = {'Anootated tweet' : 'Annotated tweet', 'Unnamed: 4': 'class'}, inplace = True)\n",
        "#d2.rename(columns = {'Anootated tweet' : 'Annotated tweet', 'Unnamed: 4': 'class'}, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgtZRGBFmeIk"
      },
      "source": [
        "train_data.dropna(how='any',subset = ['Annotated tweet', 'class'],inplace =True)\n",
        "#d2.dropna(how='any',subset = ['Annotated tweet', 'class'],inplace =True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Phe31j5z6-pJ"
      },
      "source": [
        "train_data = train_data[(train_data['class'] == 1) | (train_data['class'] == 0) | (train_data['class'] == -1) | (train_data['class'] == '1') | (train_data['class'] == '0') | (train_data['class'] == '-1')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzj2zngW4DWZ"
      },
      "source": [
        "train_data['class'] = train_data['class'].astype('int64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onT5_WnQoTgA",
        "outputId": "7d052c5b-68aa-422a-9644-525d8a4ea389"
      },
      "source": [
        "train_data['class'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1    4861\n",
              " 0    3657\n",
              " 1    2754\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2ovIalioJyY",
        "outputId": "e5396a61-c370-45be-f8ed-19c9f6331e29"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11272, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7govY3EX1v0"
      },
      "source": [
        "**DATA CLEANING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHJpH5OLXyD8"
      },
      "source": [
        "#Contractions Dictionary\n",
        "import re\n",
        "contractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\n",
        "                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\n",
        "                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n",
        "                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\n",
        "                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n",
        "                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\n",
        "                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\n",
        "                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n",
        "                     \"I'd\": \"I would\", \"I'd've\": \"I would have\",\"I'll\": \"I will\",\n",
        "                     \"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\", \"isn't\": \"is not\",\n",
        "                     \"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\n",
        "                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\n",
        "                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \n",
        "                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n",
        "                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
        "                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n",
        "                     \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n",
        "                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\n",
        "                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\n",
        "                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n",
        "                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\n",
        "                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n",
        "                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\n",
        "                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\n",
        "                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n",
        "                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n",
        "                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n",
        "                     \"what'll've\": \"what will have\",\"what're\": \"what are\", \"what've\": \"what have\",\n",
        "                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\n",
        "                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n",
        "                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\n",
        "                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\n",
        "                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
        "                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
        "                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\n",
        "                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\n",
        "                     \"you've\": \"you have\"}\n",
        "\n",
        "# Regular expression for finding contractions\n",
        "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
        "\n",
        "# Function for expanding contractions\n",
        "def expand_contractions(text,contractions_dict=contractions_dict):\n",
        "  def replace(match):\n",
        "    return contractions_dict[match.group(0)]\n",
        "  return contractions_re.sub(replace, text)\n",
        "\n",
        "# Expanding Contractions in the CONTENT feature\n",
        "train_data['Annotated tweet'] = train_data['Annotated tweet'].apply(lambda x:expand_contractions(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LJ8D6DRXyGz",
        "outputId": "dc44227c-4699-4476-e661-9fe6a6dc1f7a"
      },
      "source": [
        "# check if still there are any contractions\n",
        "for text in train_data['Annotated tweet'].to_list():\n",
        "    r = contractions_re.findall(text)\n",
        "print(r)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMW0lpSPiWvN"
      },
      "source": [
        "# Clean Data\n",
        "def read_obama_data():\n",
        "    data = pd.read_excel('/content/final-testData-no-label-Obama-tweets(2).xlsx', header = None)\n",
        "    data.rename(columns={ 0: 'index', 1:'Annotated tweet'}, inplace =True)\n",
        "    data.drop(labels = ['index'],  axis = 1, inplace = True)\n",
        "    return data\n",
        "\n",
        "def read_romney_data():\n",
        "    data = pd.read_excel('/content/final-testData-no-label-Romney-tweets(2).xlsx', header = None)\n",
        "    data.rename(columns={ 0: 'index', 1:'Annotated tweet'}, inplace =True)\n",
        "    data.drop(labels = ['index'],  axis = 1, inplace = True)\n",
        "    return data\n",
        "\n",
        "def clean_data(train_data):\n",
        "    train_data['Annotated tweet'] = train_data['Annotated tweet'].apply(lambda x:expand_contractions(x))\n",
        "    train_data['Annotated tweet'] = train_data['Annotated tweet'].apply(lambda x: bs4.BeautifulSoup(x, 'lxml').get_text())\n",
        "    train_data['Annotated tweet'] = train_data['Annotated tweet'].apply(lambda x: extract_words(x))\n",
        "    train_data['Annotated tweet'] = train_data['Annotated tweet'].apply(lambda tweet: ' '.join(re.sub(\"(@[A-Za-z0–9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())) \n",
        "    train_data['Annotated tweet'] = train_data['Annotated tweet'].apply(lambda x: re.sub('\\w*\\d\\w*','', x))\n",
        "    train_data['Annotated tweet'] = train_data['Annotated tweet'].apply(lambda x: x.lower())\n",
        "    train_data['Annotated tweet'] = train_data['Annotated tweet'].replace('\\s+', ' ', regex=True)\n",
        "    #train_data['Annotated tweet'] = train_data['Annotated tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "    #train_data['tweet_without_stopwords'] = train_data\n",
        "    train_data['Annotated tweet'] = train_data['Annotated tweet'].apply(norm_lemm_v_a_func)\n",
        "    train_data['Annotated tweet'] = train_data['Annotated tweet'].apply(lambda text : ' '.join([word for word in text.split() if len(word) > 1]))\n",
        "    train_data['Annotated tweet'] = train_data['Annotated tweet'].apply(lambda text : multiple_word_remove_func(text, words_list))\n",
        "    return train_data['Annotated tweet']\n",
        "\n",
        "def to_vectors(data):\n",
        "    data =  tfidf_vect.transform(data)\n",
        "    return data\n",
        "\n",
        "def save_obama_predictions(data):\n",
        "    preds_array = clf.predict(data)\n",
        "    with open('Obama.txt', 'w') as writefile:\n",
        "        writefile.write('82 98')\n",
        "        writefile.write(\"\\n\")\n",
        "        for index,prediction in enumerate(preds_array):\n",
        "            writefile.write(str(index+1)+';;'+ str(prediction))\n",
        "            writefile.write(\"\\n\")\n",
        "    files.download('Obama.txt')\n",
        "\n",
        "def save_romney_predictions(data):\n",
        "    preds_array = clf.predict(data)\n",
        "    with open('Romney.txt', 'w') as writefile:\n",
        "        writefile.write('82 98')\n",
        "        writefile.write(\"\\n\")\n",
        "        for index,prediction in enumerate(preds_array):\n",
        "            writefile.write(str(index+1)+';;'+ str(prediction))\n",
        "            writefile.write(\"\\n\")\n",
        "    files.download('Romney.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "193QDdLHe7nl",
        "outputId": "e4dd414d-0ff1-4abb-f50b-78b07bda5501"
      },
      "source": [
        "obama = read_obama_data()\n",
        "obama = clean_data(obama)\n",
        "obama = to_vectors(obama)\n",
        "save_obama_predictions(obama)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_6a82b168-e9d9-4cdb-be8d-f93d4b83f8aa\", \"Obama.txt\", 15427)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "pTpgj86bfMR6",
        "outputId": "f3023bb0-af85-434c-bd37-7173defae7c8"
      },
      "source": [
        "romney = read_romney_data()\n",
        "romney = clean_data(romney)\n",
        "romney = to_vectors(romney)\n",
        "save_romney_predictions(romney)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_3d6fd998-21cb-438c-af87-bedff1488145\", \"Romney.txt\", 15185)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPj-pIR9XyJg"
      },
      "source": [
        "# Removes html tags \n",
        "train_data['Annotated tweet']=train_data['Annotated tweet'].apply(lambda x: bs4.BeautifulSoup(x, 'lxml').get_text())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8LGFZFb2aSV"
      },
      "source": [
        "# Splits Hashtags\n",
        "import wordsegment as ws\n",
        "ws.load()\n",
        "def extract_words(tweet):\n",
        "    hashtags = re.findall(r\"(#\\w+)\", tweet)\n",
        "    for hs in hashtags:\n",
        "        words = \" \".join(ws.segment(hs))\n",
        "        tweet = tweet.replace(hs, words)\n",
        "    return tweet\n",
        "\n",
        "\n",
        "train_data['Annotated tweet'] = train_data['Annotated tweet'].apply(lambda x: extract_words(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viQ3UGaI2PsI"
      },
      "source": [
        "# removes urls, punctuations, emojis, hastags, mentions.\n",
        "train_data['Annotated tweet'] = train_data['Annotated tweet'].apply(lambda tweet: ' '.join(re.sub(\"(@[A-Za-z0–9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WP-t1mRYwmF"
      },
      "source": [
        "# Remove digits and words with digits\n",
        "train_data['Annotated tweet'] = train_data['Annotated tweet'].apply(lambda x: re.sub('\\w*\\d\\w*','', x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF2PqDBDYy2O"
      },
      "source": [
        "# Convert to lowercase\n",
        "train_data['Annotated tweet'] = train_data['Annotated tweet'].apply(lambda x: x.lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E2lKnWcY8R0"
      },
      "source": [
        "# Remove extra spaces\n",
        "train_data['Annotated tweet'] = train_data['Annotated tweet'].replace('\\s+', ' ', regex=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDOtJatb2xmf",
        "outputId": "e3096885-81fa-4d05-af77-c6ecec58f862"
      },
      "source": [
        "# Remove STOPWORDS\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "train_data['tweet_without_stopwords'] = train_data['Annotated tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BjtMeYElmeQ"
      },
      "source": [
        "train_data['tweet_without_stopwords'] = train_data['Annotated tweet']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ng8xMEmozu0r",
        "outputId": "04c4084d-c946-44ff-9ec2-d027c0a98aa5"
      },
      "source": [
        "# Num of words in the data after removing stopwords\n",
        "train_data['tweet_without_stopwords'].apply(lambda x: len(x.split(' '))).sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "167865"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgBpd7WMDoLP",
        "outputId": "cccf0dea-20e4-4e5d-d85b-3bf5bc8c052c"
      },
      "source": [
        "# unique words in the data\n",
        "li = []\n",
        "for l in train_data['tweet_without_stopwords'].apply(lambda x: x.split(' ')).to_list():\n",
        "    li = li + l\n",
        "len(set(li))\n",
        "# train_data['tweet_without_stopwords'].apply(lambda x: len(x.split(' '))).sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12012"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oOfBk0K0wCH",
        "outputId": "a66684ef-4b0f-4b6f-d64f-c87fd93b8cd1"
      },
      "source": [
        "max([len(x) for x in train_data['tweet_without_stopwords']])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "171"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4zFZko6ciif",
        "outputId": "7fc778e4-d06d-4a59-de31-14d9b9b61504"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "def norm_lemm_v_a_func(text):\n",
        "    words1 = word_tokenize(text)\n",
        "    text1 = ' '.join([WordNetLemmatizer().lemmatize(word, pos='v') for word in words1])\n",
        "    words2 = word_tokenize(text1)\n",
        "    text2 = ' '.join([WordNetLemmatizer().lemmatize(word, pos='a') for word in words2])\n",
        "    return text2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6M46TFadcq8",
        "outputId": "c0033952-3976-4b2d-f770-989aec30c99e"
      },
      "source": [
        "#normalization - lemmatizing\n",
        "nltk.download('punkt')\n",
        "train_data['tweet_without_stopwords'] = train_data['tweet_without_stopwords'].apply(norm_lemm_v_a_func)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acJqRn2ReXL3"
      },
      "source": [
        "# Remove single characters\n",
        "train_data['tweet_without_stopwords'] = train_data['tweet_without_stopwords'].apply(lambda text : ' '.join([word for word in text.split() if len(word) > 1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5HyL_8_hrfa"
      },
      "source": [
        "from nltk.probability import FreqDist\n",
        "def most_freq_word_func(text, n_words=5):\n",
        "    words = word_tokenize(text)\n",
        "    fdist = FreqDist(words) \n",
        "    \n",
        "    df_fdist = pd.DataFrame({'Word': fdist.keys(),\n",
        "                             'Frequency': fdist.values()})\n",
        "    df_fdist = df_fdist.sort_values(by='Frequency', ascending=False)\n",
        "    \n",
        "    n_words = n_words\n",
        "    most_freq_words_list = list(df_fdist['Word'][0:n_words])\n",
        "    \n",
        "    return most_freq_words_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiS6JSVFh2xO"
      },
      "source": [
        "def most_rare_word_func(text, n_words=5):\n",
        "    words = word_tokenize(text)\n",
        "    fdist = FreqDist(words) \n",
        "    \n",
        "    df_fdist = pd.DataFrame({'Word': fdist.keys(),\n",
        "                             'Frequency': fdist.values()})\n",
        "    df_fdist = df_fdist.sort_values(by='Frequency', ascending=False)\n",
        "    \n",
        "    n_words = n_words\n",
        "    most_rare_words_list = list(df_fdist['Word'][-n_words:])\n",
        "    \n",
        "    return most_rare_words_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92eZjd7SiBqg"
      },
      "source": [
        "text_corpus_original = train_data['tweet_without_stopwords'].str.cat(sep=' ')\n",
        "most_freq_words_list_DataFrame = most_freq_word_func(text_corpus_original, n_words=10)\n",
        "most_rare_words_list_DataFrame = most_rare_word_func(text_corpus_original, n_words=30)\n",
        "words_list = most_freq_words_list_DataFrame + most_rare_words_list_DataFrame\n",
        "words_list = [word for word in words_list if word != 'not' ]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUzSYhpAlJsJ"
      },
      "source": [
        "def multiple_word_remove_func(text, words_2_remove_list):\n",
        "    words_to_remove_list = words_2_remove_list\n",
        "    words = word_tokenize(text)\n",
        "    text = ' '.join([word for word in words if word not in words_to_remove_list])\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZxoNMSllPGl"
      },
      "source": [
        "# Remove Most common and Rarest words\n",
        "train_data['tweets_wo_freq_words'] = train_data['tweet_without_stopwords'].apply(lambda text : multiple_word_remove_func(text, words_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkizYQDemfqL"
      },
      "source": [
        "'''\n",
        "from sklearn.model_selection import train_test_split\n",
        "data1= train_data['tweets_wo_freq_words']\n",
        "labels = train_data['class']\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(data1, labels, test_size=0.2)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hRpykJ15bYJ"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=10000)\n",
        "tfidf_vect.fit(train_data['tweets_wo_freq_words'])\n",
        "X_train =  tfidf_vect.transform(train_data['tweets_wo_freq_words'])\n",
        "Y_train = train_data['class']\n",
        "#X_test =  tfidf_vect.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hGsntRhFuQE"
      },
      "source": [
        "# LR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "pahtcET482tp",
        "outputId": "6456481e-7c6c-4703-f284-0dd8491d942e"
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "scores = cross_validate(clf, X_train, Y_train, cv=5, return_train_score=False, n_jobs=-1)\n",
        "clf.fit(X_train, Y_train)\n",
        "print(\"cv test score\",scores['test_score'].mean())\n",
        "\n",
        "'''\n",
        "y_pred = clf.predict(X_test)\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "print('accuracy %s' % accuracy_score(Y_test, y_pred))\n",
        "print(classification_report( Y_test, y_pred))\n",
        "print(confusion_matrix(Y_test, y_pred))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cv test score 0.5613873537460872\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ny_pred = clf.predict(X_test)\\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\\nprint('accuracy %s' % accuracy_score(Y_test, y_pred))\\nprint(classification_report( Y_test, y_pred))\\nprint(confusion_matrix(Y_test, y_pred))\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j402IF0gF9eS"
      },
      "source": [
        "# SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "NcNEdzOvG1KE",
        "outputId": "4da14555-1506-46a8-a00c-4aed3fe2a309"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd = SGDClassifier(loss='modified_huber', max_iter=1000, tol=1e-3,   n_iter_no_change=10, early_stopping=True, n_jobs=-1 )\n",
        "scores = cross_validate(sgd, X_train, Y_train, cv=5, return_train_score=False, n_jobs=-1)\n",
        "print(\"cv test score\",scores['test_score'].mean())\n",
        "sgd.fit(X_train,Y_train)\n",
        "'''\n",
        "y_pred = sgd.predict(X_test)\n",
        "print('accuracy %s' % accuracy_score(Y_test, y_pred))\n",
        "print(classification_report( Y_test, y_pred))\n",
        "print(confusion_matrix(Y_test, y_pred))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cv test score 0.5309583947335803\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ny_pred = sgd.predict(X_test)\\nprint('accuracy %s' % accuracy_score(Y_test, y_pred))\\nprint(classification_report( Y_test, y_pred))\\nprint(confusion_matrix(Y_test, y_pred))\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XoHiCCAF27i"
      },
      "source": [
        "# Naive Baye's"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "4SlkeMp7tpdN",
        "outputId": "b3320136-9365-44cf-ffc1-b9a855bfd475"
      },
      "source": [
        "# Naive baye's\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "nb = MultinomialNB()\n",
        "scores = cross_validate(nb, X_train, Y_train, cv=5, return_train_score=False, n_jobs=-1)\n",
        "print(\"cv test score\",scores['test_score'].mean())\n",
        "nb.fit(X_train, Y_train)\n",
        "'''\n",
        "y_pred = nb.predict(X_test)\n",
        "print('accuracy %s' % accuracy_score(Y_test, y_pred))\n",
        "print(classification_report(Y_test, y_pred))\n",
        "print(confusion_matrix(Y_test, y_pred))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cv test score 0.5265224277313354\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ny_pred = nb.predict(X_test)\\nprint('accuracy %s' % accuracy_score(Y_test, y_pred))\\nprint(classification_report(Y_test, y_pred))\\nprint(confusion_matrix(Y_test, y_pred))\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrsCbHOhMpa1"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "n8vERw4XMsGU",
        "outputId": "7dc73225-9ffa-4965-af27-d701abbc8951"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(bootstrap=True,min_impurity_decrease=1e-7,n_jobs=-1, random_state=42)\n",
        "scores = cross_validate(rf, X_train, Y_train, cv=5, return_train_score=False, n_jobs=-1)\n",
        "print(\"cv test score\",scores['test_score'].mean())\n",
        "rf.fit(X_train, Y_train)\n",
        "'''\n",
        "y_pred = rf.predict(X_test)\n",
        "print('accuracy %s' % accuracy_score(Y_test, y_pred))\n",
        "print(classification_report(Y_test, y_pred))\n",
        "print(confusion_matrix(Y_test, y_pred))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cv test score 0.5514519445105719\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ny_pred = rf.predict(X_test)\\nprint('accuracy %s' % accuracy_score(Y_test, y_pred))\\nprint(classification_report(Y_test, y_pred))\\nprint(confusion_matrix(Y_test, y_pred))\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6W1-uagwRMVB"
      },
      "source": [
        "# XgBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "xT91b15wROf2",
        "outputId": "4fb360ac-5193-4eb3-cb73-ebd27cc2fb8c"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "#fit_params={'early_stopping_rounds':10}\n",
        "xgb = XGBClassifier(n_estimators=1000, subsample=0.8)\n",
        "scores = cross_validate(xgb, X_train, Y_train, cv=5, return_train_score=False, n_jobs=-1)\n",
        "print(\"cv test score\",scores['test_score'].mean())\n",
        "xgb.fit(X_train, Y_train)\n",
        "'''\n",
        "y_pred = xgb.predict(X_test)\n",
        "print('accuracy %s' % accuracy_score(Y_test, y_pred))\n",
        "print(classification_report(Y_test, y_pred))\n",
        "print(confusion_matrix(Y_test, y_pred))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cv test score 0.5498559250172642\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ny_pred = xgb.predict(X_test)\\nprint('accuracy %s' % accuracy_score(Y_test, y_pred))\\nprint(classification_report(Y_test, y_pred))\\nprint(confusion_matrix(Y_test, y_pred))\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8pqJRQQHOBg"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "8GNlDZtgHPuM",
        "outputId": "f83c56e8-8c06-4522-818a-7f9c1407e0b5"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_validate\n",
        "s = svm.SVC(kernel = 'linear', gamma=0.1)\n",
        "scores = cross_validate(s, X_train, Y_train, cv=5, return_train_score=False, n_jobs=-1)\n",
        "print(\"cv test score\",scores['test_score'].mean())\n",
        "s.fit(X_train, Y_train)\n",
        "\n",
        "'''\n",
        "y_pred = s.predict(X_test)\n",
        "print('accuracy %s' % accuracy_score(Y_test, y_pred))\n",
        "print(classification_report(Y_test, y_pred))\n",
        "print(confusion_matrix(Y_test, y_pred))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cv test score 0.5550000885344015\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ny_pred = s.predict(X_test)\\nprint('accuracy %s' % accuracy_score(Y_test, y_pred))\\nprint(classification_report(Y_test, y_pred))\\nprint(confusion_matrix(Y_test, y_pred))\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQiOlYvW2gQR",
        "outputId": "e3855bc2-d1cc-4e0c-a57b-1e2d3a8403b8"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import svm\n",
        "# defining parameter range\n",
        "param_grid = { 'C':[0.1,1,100,1000],'kernel':['linear'],'degree':[3,4,5,6],'gamma': [1, 0.1, 0.01, 0.001, 0.0001]}\n",
        "grid = GridSearchCV(svm.SVC(), param_grid, refit = True, verbose = 3)\n",
        "# fitting the model for grid search\n",
        "grid.fit(X_train, Y_train)\n",
        "grid_search.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
            "[CV 1/5] END C=0.1, degree=3, gamma=1, kernel=linear;, score=0.503 total time=  14.8s\n",
            "[CV 2/5] END C=0.1, degree=3, gamma=1, kernel=linear;, score=0.504 total time=  15.8s\n",
            "[CV 3/5] END C=0.1, degree=3, gamma=1, kernel=linear;, score=0.496 total time=  14.8s\n",
            "[CV 4/5] END C=0.1, degree=3, gamma=1, kernel=linear;, score=0.465 total time=  15.3s\n",
            "[CV 5/5] END C=0.1, degree=3, gamma=1, kernel=linear;, score=0.469 total time=  15.0s\n",
            "[CV 1/5] END C=0.1, degree=3, gamma=0.1, kernel=linear;, score=0.503 total time=  15.1s\n",
            "[CV 2/5] END C=0.1, degree=3, gamma=0.1, kernel=linear;, score=0.504 total time=  14.6s\n",
            "[CV 3/5] END C=0.1, degree=3, gamma=0.1, kernel=linear;, score=0.496 total time=  15.1s\n",
            "[CV 4/5] END C=0.1, degree=3, gamma=0.1, kernel=linear;, score=0.465 total time=  14.7s\n",
            "[CV 5/5] END C=0.1, degree=3, gamma=0.1, kernel=linear;, score=0.469 total time=  15.2s\n",
            "[CV 1/5] END C=0.1, degree=3, gamma=0.01, kernel=linear;, score=0.503 total time=  14.6s\n",
            "[CV 2/5] END C=0.1, degree=3, gamma=0.01, kernel=linear;, score=0.504 total time=  14.9s\n",
            "[CV 3/5] END C=0.1, degree=3, gamma=0.01, kernel=linear;, score=0.496 total time=  14.8s\n",
            "[CV 4/5] END C=0.1, degree=3, gamma=0.01, kernel=linear;, score=0.465 total time=  15.1s\n",
            "[CV 5/5] END C=0.1, degree=3, gamma=0.01, kernel=linear;, score=0.469 total time=  14.9s\n",
            "[CV 1/5] END C=0.1, degree=3, gamma=0.001, kernel=linear;, score=0.503 total time=  14.8s\n",
            "[CV 2/5] END C=0.1, degree=3, gamma=0.001, kernel=linear;, score=0.504 total time=  14.6s\n",
            "[CV 3/5] END C=0.1, degree=3, gamma=0.001, kernel=linear;, score=0.496 total time=  14.9s\n",
            "[CV 4/5] END C=0.1, degree=3, gamma=0.001, kernel=linear;, score=0.465 total time=  14.3s\n",
            "[CV 5/5] END C=0.1, degree=3, gamma=0.001, kernel=linear;, score=0.469 total time=  14.8s\n",
            "[CV 1/5] END C=0.1, degree=3, gamma=0.0001, kernel=linear;, score=0.503 total time=  14.4s\n",
            "[CV 2/5] END C=0.1, degree=3, gamma=0.0001, kernel=linear;, score=0.504 total time=  14.8s\n",
            "[CV 3/5] END C=0.1, degree=3, gamma=0.0001, kernel=linear;, score=0.496 total time=  14.6s\n",
            "[CV 4/5] END C=0.1, degree=3, gamma=0.0001, kernel=linear;, score=0.465 total time=  14.4s\n",
            "[CV 5/5] END C=0.1, degree=3, gamma=0.0001, kernel=linear;, score=0.469 total time=  14.8s\n",
            "[CV 1/5] END C=0.1, degree=4, gamma=1, kernel=linear;, score=0.503 total time=  14.6s\n",
            "[CV 2/5] END C=0.1, degree=4, gamma=1, kernel=linear;, score=0.504 total time=  14.6s\n",
            "[CV 3/5] END C=0.1, degree=4, gamma=1, kernel=linear;, score=0.496 total time=  14.6s\n",
            "[CV 4/5] END C=0.1, degree=4, gamma=1, kernel=linear;, score=0.465 total time=  14.5s\n",
            "[CV 5/5] END C=0.1, degree=4, gamma=1, kernel=linear;, score=0.469 total time=  15.2s\n",
            "[CV 1/5] END C=0.1, degree=4, gamma=0.1, kernel=linear;, score=0.503 total time=  14.3s\n",
            "[CV 2/5] END C=0.1, degree=4, gamma=0.1, kernel=linear;, score=0.504 total time=  14.7s\n",
            "[CV 3/5] END C=0.1, degree=4, gamma=0.1, kernel=linear;, score=0.496 total time=  14.5s\n",
            "[CV 4/5] END C=0.1, degree=4, gamma=0.1, kernel=linear;, score=0.465 total time=  14.4s\n",
            "[CV 5/5] END C=0.1, degree=4, gamma=0.1, kernel=linear;, score=0.469 total time=  14.5s\n",
            "[CV 1/5] END C=0.1, degree=4, gamma=0.01, kernel=linear;, score=0.503 total time=  14.5s\n",
            "[CV 2/5] END C=0.1, degree=4, gamma=0.01, kernel=linear;, score=0.504 total time=  14.4s\n",
            "[CV 3/5] END C=0.1, degree=4, gamma=0.01, kernel=linear;, score=0.496 total time=  14.6s\n",
            "[CV 4/5] END C=0.1, degree=4, gamma=0.01, kernel=linear;, score=0.465 total time=  14.2s\n",
            "[CV 5/5] END C=0.1, degree=4, gamma=0.01, kernel=linear;, score=0.469 total time=  14.7s\n",
            "[CV 1/5] END C=0.1, degree=4, gamma=0.001, kernel=linear;, score=0.503 total time=  14.3s\n",
            "[CV 2/5] END C=0.1, degree=4, gamma=0.001, kernel=linear;, score=0.504 total time=  14.6s\n",
            "[CV 3/5] END C=0.1, degree=4, gamma=0.001, kernel=linear;, score=0.496 total time=  14.5s\n",
            "[CV 4/5] END C=0.1, degree=4, gamma=0.001, kernel=linear;, score=0.465 total time=  14.3s\n",
            "[CV 5/5] END C=0.1, degree=4, gamma=0.001, kernel=linear;, score=0.469 total time=  14.6s\n",
            "[CV 1/5] END C=0.1, degree=4, gamma=0.0001, kernel=linear;, score=0.503 total time=  14.6s\n",
            "[CV 2/5] END C=0.1, degree=4, gamma=0.0001, kernel=linear;, score=0.504 total time=  14.5s\n",
            "[CV 3/5] END C=0.1, degree=4, gamma=0.0001, kernel=linear;, score=0.496 total time=  14.7s\n",
            "[CV 4/5] END C=0.1, degree=4, gamma=0.0001, kernel=linear;, score=0.465 total time=  14.2s\n",
            "[CV 5/5] END C=0.1, degree=4, gamma=0.0001, kernel=linear;, score=0.469 total time=  14.9s\n",
            "[CV 1/5] END C=0.1, degree=5, gamma=1, kernel=linear;, score=0.503 total time=  14.4s\n",
            "[CV 2/5] END C=0.1, degree=5, gamma=1, kernel=linear;, score=0.504 total time=  14.6s\n",
            "[CV 3/5] END C=0.1, degree=5, gamma=1, kernel=linear;, score=0.496 total time=  14.5s\n",
            "[CV 4/5] END C=0.1, degree=5, gamma=1, kernel=linear;, score=0.465 total time=  14.5s\n",
            "[CV 5/5] END C=0.1, degree=5, gamma=1, kernel=linear;, score=0.469 total time=  14.7s\n",
            "[CV 1/5] END C=0.1, degree=5, gamma=0.1, kernel=linear;, score=0.503 total time=  14.5s\n",
            "[CV 2/5] END C=0.1, degree=5, gamma=0.1, kernel=linear;, score=0.504 total time=  14.5s\n",
            "[CV 3/5] END C=0.1, degree=5, gamma=0.1, kernel=linear;, score=0.496 total time=  14.8s\n",
            "[CV 4/5] END C=0.1, degree=5, gamma=0.1, kernel=linear;, score=0.465 total time=  14.3s\n",
            "[CV 5/5] END C=0.1, degree=5, gamma=0.1, kernel=linear;, score=0.469 total time=  14.7s\n",
            "[CV 1/5] END C=0.1, degree=5, gamma=0.01, kernel=linear;, score=0.503 total time=  14.3s\n",
            "[CV 2/5] END C=0.1, degree=5, gamma=0.01, kernel=linear;, score=0.504 total time=  14.7s\n",
            "[CV 3/5] END C=0.1, degree=5, gamma=0.01, kernel=linear;, score=0.496 total time=  14.5s\n",
            "[CV 4/5] END C=0.1, degree=5, gamma=0.01, kernel=linear;, score=0.465 total time=  14.4s\n",
            "[CV 5/5] END C=0.1, degree=5, gamma=0.01, kernel=linear;, score=0.469 total time=  14.6s\n",
            "[CV 1/5] END C=0.1, degree=5, gamma=0.001, kernel=linear;, score=0.503 total time=  14.5s\n",
            "[CV 2/5] END C=0.1, degree=5, gamma=0.001, kernel=linear;, score=0.504 total time=  14.5s\n",
            "[CV 3/5] END C=0.1, degree=5, gamma=0.001, kernel=linear;, score=0.496 total time=  14.8s\n",
            "[CV 4/5] END C=0.1, degree=5, gamma=0.001, kernel=linear;, score=0.465 total time=  14.3s\n",
            "[CV 5/5] END C=0.1, degree=5, gamma=0.001, kernel=linear;, score=0.469 total time=  14.9s\n",
            "[CV 1/5] END C=0.1, degree=5, gamma=0.0001, kernel=linear;, score=0.503 total time=  14.7s\n",
            "[CV 2/5] END C=0.1, degree=5, gamma=0.0001, kernel=linear;, score=0.504 total time=  14.8s\n",
            "[CV 3/5] END C=0.1, degree=5, gamma=0.0001, kernel=linear;, score=0.496 total time=  14.8s\n",
            "[CV 4/5] END C=0.1, degree=5, gamma=0.0001, kernel=linear;, score=0.465 total time=  14.4s\n",
            "[CV 5/5] END C=0.1, degree=5, gamma=0.0001, kernel=linear;, score=0.469 total time=  14.8s\n",
            "[CV 1/5] END C=0.1, degree=6, gamma=1, kernel=linear;, score=0.503 total time=  14.5s\n",
            "[CV 2/5] END C=0.1, degree=6, gamma=1, kernel=linear;, score=0.504 total time=  14.6s\n",
            "[CV 3/5] END C=0.1, degree=6, gamma=1, kernel=linear;, score=0.496 total time=  14.7s\n",
            "[CV 4/5] END C=0.1, degree=6, gamma=1, kernel=linear;, score=0.465 total time=  14.4s\n",
            "[CV 5/5] END C=0.1, degree=6, gamma=1, kernel=linear;, score=0.469 total time=  15.0s\n",
            "[CV 1/5] END C=0.1, degree=6, gamma=0.1, kernel=linear;, score=0.503 total time=  14.4s\n",
            "[CV 2/5] END C=0.1, degree=6, gamma=0.1, kernel=linear;, score=0.504 total time=  14.7s\n",
            "[CV 3/5] END C=0.1, degree=6, gamma=0.1, kernel=linear;, score=0.496 total time=  14.6s\n",
            "[CV 4/5] END C=0.1, degree=6, gamma=0.1, kernel=linear;, score=0.465 total time=  14.5s\n",
            "[CV 5/5] END C=0.1, degree=6, gamma=0.1, kernel=linear;, score=0.469 total time=  14.7s\n",
            "[CV 1/5] END C=0.1, degree=6, gamma=0.01, kernel=linear;, score=0.503 total time=  14.5s\n",
            "[CV 2/5] END C=0.1, degree=6, gamma=0.01, kernel=linear;, score=0.504 total time=  14.7s\n",
            "[CV 3/5] END C=0.1, degree=6, gamma=0.01, kernel=linear;, score=0.496 total time=  15.0s\n",
            "[CV 4/5] END C=0.1, degree=6, gamma=0.01, kernel=linear;, score=0.465 total time=  14.4s\n",
            "[CV 5/5] END C=0.1, degree=6, gamma=0.01, kernel=linear;, score=0.469 total time=  14.9s\n",
            "[CV 1/5] END C=0.1, degree=6, gamma=0.001, kernel=linear;, score=0.503 total time=  14.6s\n",
            "[CV 2/5] END C=0.1, degree=6, gamma=0.001, kernel=linear;, score=0.504 total time=  15.0s\n",
            "[CV 3/5] END C=0.1, degree=6, gamma=0.001, kernel=linear;, score=0.496 total time=  14.7s\n",
            "[CV 4/5] END C=0.1, degree=6, gamma=0.001, kernel=linear;, score=0.465 total time=  14.6s\n",
            "[CV 5/5] END C=0.1, degree=6, gamma=0.001, kernel=linear;, score=0.469 total time=  15.0s\n",
            "[CV 1/5] END C=0.1, degree=6, gamma=0.0001, kernel=linear;, score=0.503 total time=  14.7s\n",
            "[CV 2/5] END C=0.1, degree=6, gamma=0.0001, kernel=linear;, score=0.504 total time=  14.6s\n",
            "[CV 3/5] END C=0.1, degree=6, gamma=0.0001, kernel=linear;, score=0.496 total time=  14.9s\n",
            "[CV 4/5] END C=0.1, degree=6, gamma=0.0001, kernel=linear;, score=0.465 total time=  14.4s\n",
            "[CV 5/5] END C=0.1, degree=6, gamma=0.0001, kernel=linear;, score=0.469 total time=  15.1s\n",
            "[CV 1/5] END C=1, degree=3, gamma=1, kernel=linear;, score=0.556 total time=  13.9s\n",
            "[CV 2/5] END C=1, degree=3, gamma=1, kernel=linear;, score=0.593 total time=  14.3s\n",
            "[CV 3/5] END C=1, degree=3, gamma=1, kernel=linear;, score=0.574 total time=  14.1s\n",
            "[CV 4/5] END C=1, degree=3, gamma=1, kernel=linear;, score=0.529 total time=  13.9s\n",
            "[CV 5/5] END C=1, degree=3, gamma=1, kernel=linear;, score=0.524 total time=  14.0s\n",
            "[CV 1/5] END C=1, degree=3, gamma=0.1, kernel=linear;, score=0.556 total time=  14.0s\n",
            "[CV 2/5] END C=1, degree=3, gamma=0.1, kernel=linear;, score=0.593 total time=  14.2s\n",
            "[CV 3/5] END C=1, degree=3, gamma=0.1, kernel=linear;, score=0.574 total time=  14.3s\n",
            "[CV 4/5] END C=1, degree=3, gamma=0.1, kernel=linear;, score=0.529 total time=  13.8s\n",
            "[CV 5/5] END C=1, degree=3, gamma=0.1, kernel=linear;, score=0.524 total time=  14.2s\n",
            "[CV 1/5] END C=1, degree=3, gamma=0.01, kernel=linear;, score=0.556 total time=  14.3s\n",
            "[CV 2/5] END C=1, degree=3, gamma=0.01, kernel=linear;, score=0.593 total time=  15.5s\n",
            "[CV 3/5] END C=1, degree=3, gamma=0.01, kernel=linear;, score=0.574 total time=  15.4s\n",
            "[CV 4/5] END C=1, degree=3, gamma=0.01, kernel=linear;, score=0.529 total time=  14.1s\n",
            "[CV 5/5] END C=1, degree=3, gamma=0.01, kernel=linear;, score=0.524 total time=  14.2s\n",
            "[CV 1/5] END C=1, degree=3, gamma=0.001, kernel=linear;, score=0.556 total time=  14.4s\n",
            "[CV 2/5] END C=1, degree=3, gamma=0.001, kernel=linear;, score=0.593 total time=  15.0s\n",
            "[CV 3/5] END C=1, degree=3, gamma=0.001, kernel=linear;, score=0.574 total time=  15.4s\n",
            "[CV 4/5] END C=1, degree=3, gamma=0.001, kernel=linear;, score=0.529 total time=  14.8s\n",
            "[CV 5/5] END C=1, degree=3, gamma=0.001, kernel=linear;, score=0.524 total time=  15.6s\n",
            "[CV 1/5] END C=1, degree=3, gamma=0.0001, kernel=linear;, score=0.556 total time=  15.2s\n",
            "[CV 2/5] END C=1, degree=3, gamma=0.0001, kernel=linear;, score=0.593 total time=  15.6s\n",
            "[CV 3/5] END C=1, degree=3, gamma=0.0001, kernel=linear;, score=0.574 total time=  15.3s\n",
            "[CV 4/5] END C=1, degree=3, gamma=0.0001, kernel=linear;, score=0.529 total time=  14.1s\n",
            "[CV 5/5] END C=1, degree=3, gamma=0.0001, kernel=linear;, score=0.524 total time=  15.0s\n",
            "[CV 1/5] END C=1, degree=4, gamma=1, kernel=linear;, score=0.556 total time=  14.7s\n",
            "[CV 2/5] END C=1, degree=4, gamma=1, kernel=linear;, score=0.593 total time=  14.4s\n",
            "[CV 3/5] END C=1, degree=4, gamma=1, kernel=linear;, score=0.574 total time=  14.6s\n",
            "[CV 4/5] END C=1, degree=4, gamma=1, kernel=linear;, score=0.529 total time=  14.1s\n",
            "[CV 5/5] END C=1, degree=4, gamma=1, kernel=linear;, score=0.524 total time=  14.7s\n",
            "[CV 1/5] END C=1, degree=4, gamma=0.1, kernel=linear;, score=0.556 total time=  15.4s\n",
            "[CV 2/5] END C=1, degree=4, gamma=0.1, kernel=linear;, score=0.593 total time=  16.2s\n",
            "[CV 3/5] END C=1, degree=4, gamma=0.1, kernel=linear;, score=0.574 total time=  16.0s\n",
            "[CV 4/5] END C=1, degree=4, gamma=0.1, kernel=linear;, score=0.529 total time=  15.2s\n",
            "[CV 5/5] END C=1, degree=4, gamma=0.1, kernel=linear;, score=0.524 total time=  14.4s\n",
            "[CV 1/5] END C=1, degree=4, gamma=0.01, kernel=linear;, score=0.556 total time=  14.4s\n",
            "[CV 2/5] END C=1, degree=4, gamma=0.01, kernel=linear;, score=0.593 total time=  14.5s\n",
            "[CV 3/5] END C=1, degree=4, gamma=0.01, kernel=linear;, score=0.574 total time=  14.9s\n",
            "[CV 4/5] END C=1, degree=4, gamma=0.01, kernel=linear;, score=0.529 total time=  14.1s\n",
            "[CV 5/5] END C=1, degree=4, gamma=0.01, kernel=linear;, score=0.524 total time=  14.2s\n",
            "[CV 1/5] END C=1, degree=4, gamma=0.001, kernel=linear;, score=0.556 total time=  13.9s\n",
            "[CV 2/5] END C=1, degree=4, gamma=0.001, kernel=linear;, score=0.593 total time=  14.3s\n",
            "[CV 3/5] END C=1, degree=4, gamma=0.001, kernel=linear;, score=0.574 total time=  14.0s\n",
            "[CV 4/5] END C=1, degree=4, gamma=0.001, kernel=linear;, score=0.529 total time=  13.9s\n",
            "[CV 5/5] END C=1, degree=4, gamma=0.001, kernel=linear;, score=0.524 total time=  14.0s\n",
            "[CV 1/5] END C=1, degree=4, gamma=0.0001, kernel=linear;, score=0.556 total time=  14.0s\n",
            "[CV 2/5] END C=1, degree=4, gamma=0.0001, kernel=linear;, score=0.593 total time=  14.1s\n",
            "[CV 3/5] END C=1, degree=4, gamma=0.0001, kernel=linear;, score=0.574 total time=  14.2s\n",
            "[CV 4/5] END C=1, degree=4, gamma=0.0001, kernel=linear;, score=0.529 total time=  13.9s\n",
            "[CV 5/5] END C=1, degree=4, gamma=0.0001, kernel=linear;, score=0.524 total time=  14.2s\n",
            "[CV 1/5] END C=1, degree=5, gamma=1, kernel=linear;, score=0.556 total time=  13.8s\n",
            "[CV 2/5] END C=1, degree=5, gamma=1, kernel=linear;, score=0.593 total time=  14.2s\n",
            "[CV 3/5] END C=1, degree=5, gamma=1, kernel=linear;, score=0.574 total time=  14.2s\n",
            "[CV 4/5] END C=1, degree=5, gamma=1, kernel=linear;, score=0.529 total time=  13.8s\n",
            "[CV 5/5] END C=1, degree=5, gamma=1, kernel=linear;, score=0.524 total time=  14.0s\n",
            "[CV 1/5] END C=1, degree=5, gamma=0.1, kernel=linear;, score=0.556 total time=  13.9s\n",
            "[CV 2/5] END C=1, degree=5, gamma=0.1, kernel=linear;, score=0.593 total time=  14.3s\n",
            "[CV 3/5] END C=1, degree=5, gamma=0.1, kernel=linear;, score=0.574 total time=  14.2s\n",
            "[CV 4/5] END C=1, degree=5, gamma=0.1, kernel=linear;, score=0.529 total time=  13.8s\n",
            "[CV 5/5] END C=1, degree=5, gamma=0.1, kernel=linear;, score=0.524 total time=  14.2s\n",
            "[CV 1/5] END C=1, degree=5, gamma=0.01, kernel=linear;, score=0.556 total time=  13.8s\n",
            "[CV 2/5] END C=1, degree=5, gamma=0.01, kernel=linear;, score=0.593 total time=  14.3s\n",
            "[CV 3/5] END C=1, degree=5, gamma=0.01, kernel=linear;, score=0.574 total time=  14.1s\n",
            "[CV 4/5] END C=1, degree=5, gamma=0.01, kernel=linear;, score=0.529 total time=  13.9s\n",
            "[CV 5/5] END C=1, degree=5, gamma=0.01, kernel=linear;, score=0.524 total time=  14.0s\n",
            "[CV 1/5] END C=1, degree=5, gamma=0.001, kernel=linear;, score=0.556 total time=  13.9s\n",
            "[CV 2/5] END C=1, degree=5, gamma=0.001, kernel=linear;, score=0.593 total time=  14.2s\n",
            "[CV 3/5] END C=1, degree=5, gamma=0.001, kernel=linear;, score=0.574 total time=  14.2s\n",
            "[CV 4/5] END C=1, degree=5, gamma=0.001, kernel=linear;, score=0.529 total time=  13.8s\n",
            "[CV 5/5] END C=1, degree=5, gamma=0.001, kernel=linear;, score=0.524 total time=  14.2s\n",
            "[CV 1/5] END C=1, degree=5, gamma=0.0001, kernel=linear;, score=0.556 total time=  13.9s\n",
            "[CV 2/5] END C=1, degree=5, gamma=0.0001, kernel=linear;, score=0.593 total time=  14.3s\n",
            "[CV 3/5] END C=1, degree=5, gamma=0.0001, kernel=linear;, score=0.574 total time=  14.0s\n",
            "[CV 4/5] END C=1, degree=5, gamma=0.0001, kernel=linear;, score=0.529 total time=  13.9s\n",
            "[CV 5/5] END C=1, degree=5, gamma=0.0001, kernel=linear;, score=0.524 total time=  14.1s\n",
            "[CV 1/5] END C=1, degree=6, gamma=1, kernel=linear;, score=0.556 total time=  14.0s\n",
            "[CV 2/5] END C=1, degree=6, gamma=1, kernel=linear;, score=0.593 total time=  14.2s\n",
            "[CV 3/5] END C=1, degree=6, gamma=1, kernel=linear;, score=0.574 total time=  14.2s\n",
            "[CV 4/5] END C=1, degree=6, gamma=1, kernel=linear;, score=0.529 total time=  13.9s\n",
            "[CV 5/5] END C=1, degree=6, gamma=1, kernel=linear;, score=0.524 total time=  14.2s\n",
            "[CV 1/5] END C=1, degree=6, gamma=0.1, kernel=linear;, score=0.556 total time=  13.9s\n",
            "[CV 2/5] END C=1, degree=6, gamma=0.1, kernel=linear;, score=0.593 total time=  14.3s\n",
            "[CV 3/5] END C=1, degree=6, gamma=0.1, kernel=linear;, score=0.574 total time=  14.1s\n",
            "[CV 4/5] END C=1, degree=6, gamma=0.1, kernel=linear;, score=0.529 total time=  13.8s\n",
            "[CV 5/5] END C=1, degree=6, gamma=0.1, kernel=linear;, score=0.524 total time=  14.0s\n",
            "[CV 1/5] END C=1, degree=6, gamma=0.01, kernel=linear;, score=0.556 total time=  13.9s\n",
            "[CV 2/5] END C=1, degree=6, gamma=0.01, kernel=linear;, score=0.593 total time=  14.2s\n",
            "[CV 3/5] END C=1, degree=6, gamma=0.01, kernel=linear;, score=0.574 total time=  14.1s\n",
            "[CV 4/5] END C=1, degree=6, gamma=0.01, kernel=linear;, score=0.529 total time=  13.8s\n",
            "[CV 5/5] END C=1, degree=6, gamma=0.01, kernel=linear;, score=0.524 total time=  14.1s\n",
            "[CV 1/5] END C=1, degree=6, gamma=0.001, kernel=linear;, score=0.556 total time=  13.9s\n",
            "[CV 2/5] END C=1, degree=6, gamma=0.001, kernel=linear;, score=0.593 total time=  14.3s\n",
            "[CV 3/5] END C=1, degree=6, gamma=0.001, kernel=linear;, score=0.574 total time=  14.0s\n",
            "[CV 4/5] END C=1, degree=6, gamma=0.001, kernel=linear;, score=0.529 total time=  13.8s\n",
            "[CV 5/5] END C=1, degree=6, gamma=0.001, kernel=linear;, score=0.524 total time=  14.0s\n",
            "[CV 1/5] END C=1, degree=6, gamma=0.0001, kernel=linear;, score=0.556 total time=  14.0s\n",
            "[CV 2/5] END C=1, degree=6, gamma=0.0001, kernel=linear;, score=0.593 total time=  14.2s\n",
            "[CV 3/5] END C=1, degree=6, gamma=0.0001, kernel=linear;, score=0.574 total time=  14.2s\n",
            "[CV 4/5] END C=1, degree=6, gamma=0.0001, kernel=linear;, score=0.529 total time=  13.7s\n",
            "[CV 5/5] END C=1, degree=6, gamma=0.0001, kernel=linear;, score=0.524 total time=  14.1s\n",
            "[CV 1/5] END C=100, degree=3, gamma=1, kernel=linear;, score=0.498 total time=  39.1s\n",
            "[CV 2/5] END C=100, degree=3, gamma=1, kernel=linear;, score=0.522 total time=  36.0s\n",
            "[CV 3/5] END C=100, degree=3, gamma=1, kernel=linear;, score=0.491 total time=  35.6s\n",
            "[CV 4/5] END C=100, degree=3, gamma=1, kernel=linear;, score=0.469 total time=  38.6s\n",
            "[CV 5/5] END C=100, degree=3, gamma=1, kernel=linear;, score=0.474 total time=  33.7s\n",
            "[CV 1/5] END C=100, degree=3, gamma=0.1, kernel=linear;, score=0.498 total time=  39.2s\n",
            "[CV 2/5] END C=100, degree=3, gamma=0.1, kernel=linear;, score=0.522 total time=  35.9s\n",
            "[CV 3/5] END C=100, degree=3, gamma=0.1, kernel=linear;, score=0.491 total time=  35.7s\n",
            "[CV 4/5] END C=100, degree=3, gamma=0.1, kernel=linear;, score=0.469 total time=  38.7s\n",
            "[CV 5/5] END C=100, degree=3, gamma=0.1, kernel=linear;, score=0.474 total time=  33.9s\n",
            "[CV 1/5] END C=100, degree=3, gamma=0.01, kernel=linear;, score=0.498 total time=  39.4s\n",
            "[CV 2/5] END C=100, degree=3, gamma=0.01, kernel=linear;, score=0.522 total time=  36.2s\n",
            "[CV 3/5] END C=100, degree=3, gamma=0.01, kernel=linear;, score=0.491 total time=  36.1s\n",
            "[CV 4/5] END C=100, degree=3, gamma=0.01, kernel=linear;, score=0.469 total time=  39.1s\n",
            "[CV 5/5] END C=100, degree=3, gamma=0.01, kernel=linear;, score=0.474 total time=  34.0s\n",
            "[CV 1/5] END C=100, degree=3, gamma=0.001, kernel=linear;, score=0.498 total time=  39.4s\n",
            "[CV 2/5] END C=100, degree=3, gamma=0.001, kernel=linear;, score=0.522 total time=  36.0s\n",
            "[CV 3/5] END C=100, degree=3, gamma=0.001, kernel=linear;, score=0.491 total time=  35.9s\n",
            "[CV 4/5] END C=100, degree=3, gamma=0.001, kernel=linear;, score=0.469 total time=  38.7s\n",
            "[CV 5/5] END C=100, degree=3, gamma=0.001, kernel=linear;, score=0.474 total time=  33.9s\n",
            "[CV 1/5] END C=100, degree=3, gamma=0.0001, kernel=linear;, score=0.498 total time=  39.3s\n",
            "[CV 2/5] END C=100, degree=3, gamma=0.0001, kernel=linear;, score=0.522 total time=  36.1s\n",
            "[CV 3/5] END C=100, degree=3, gamma=0.0001, kernel=linear;, score=0.491 total time=  35.8s\n",
            "[CV 4/5] END C=100, degree=3, gamma=0.0001, kernel=linear;, score=0.469 total time=  38.7s\n",
            "[CV 5/5] END C=100, degree=3, gamma=0.0001, kernel=linear;, score=0.474 total time=  33.9s\n",
            "[CV 1/5] END C=100, degree=4, gamma=1, kernel=linear;, score=0.498 total time=  39.5s\n",
            "[CV 2/5] END C=100, degree=4, gamma=1, kernel=linear;, score=0.522 total time=  36.3s\n",
            "[CV 3/5] END C=100, degree=4, gamma=1, kernel=linear;, score=0.491 total time=  36.2s\n",
            "[CV 4/5] END C=100, degree=4, gamma=1, kernel=linear;, score=0.469 total time=  38.9s\n",
            "[CV 5/5] END C=100, degree=4, gamma=1, kernel=linear;, score=0.474 total time=  34.1s\n",
            "[CV 1/5] END C=100, degree=4, gamma=0.1, kernel=linear;, score=0.498 total time=  39.6s\n",
            "[CV 2/5] END C=100, degree=4, gamma=0.1, kernel=linear;, score=0.522 total time=  36.3s\n",
            "[CV 3/5] END C=100, degree=4, gamma=0.1, kernel=linear;, score=0.491 total time=  35.9s\n",
            "[CV 4/5] END C=100, degree=4, gamma=0.1, kernel=linear;, score=0.469 total time=  38.9s\n",
            "[CV 5/5] END C=100, degree=4, gamma=0.1, kernel=linear;, score=0.474 total time=  34.1s\n",
            "[CV 1/5] END C=100, degree=4, gamma=0.01, kernel=linear;, score=0.498 total time=  39.6s\n",
            "[CV 2/5] END C=100, degree=4, gamma=0.01, kernel=linear;, score=0.522 total time=  36.1s\n",
            "[CV 3/5] END C=100, degree=4, gamma=0.01, kernel=linear;, score=0.491 total time=  36.3s\n",
            "[CV 4/5] END C=100, degree=4, gamma=0.01, kernel=linear;, score=0.469 total time=  39.2s\n",
            "[CV 5/5] END C=100, degree=4, gamma=0.01, kernel=linear;, score=0.474 total time=  34.2s\n",
            "[CV 1/5] END C=100, degree=4, gamma=0.001, kernel=linear;, score=0.498 total time=  39.6s\n",
            "[CV 2/5] END C=100, degree=4, gamma=0.001, kernel=linear;, score=0.522 total time=  37.1s\n",
            "[CV 3/5] END C=100, degree=4, gamma=0.001, kernel=linear;, score=0.491 total time=  36.7s\n",
            "[CV 4/5] END C=100, degree=4, gamma=0.001, kernel=linear;, score=0.469 total time=  39.9s\n",
            "[CV 5/5] END C=100, degree=4, gamma=0.001, kernel=linear;, score=0.474 total time=  34.6s\n",
            "[CV 1/5] END C=100, degree=4, gamma=0.0001, kernel=linear;, score=0.498 total time=  41.0s\n",
            "[CV 2/5] END C=100, degree=4, gamma=0.0001, kernel=linear;, score=0.522 total time=  38.1s\n",
            "[CV 3/5] END C=100, degree=4, gamma=0.0001, kernel=linear;, score=0.491 total time=  38.2s\n",
            "[CV 4/5] END C=100, degree=4, gamma=0.0001, kernel=linear;, score=0.469 total time=  40.3s\n",
            "[CV 5/5] END C=100, degree=4, gamma=0.0001, kernel=linear;, score=0.474 total time=  35.6s\n",
            "[CV 1/5] END C=100, degree=5, gamma=1, kernel=linear;, score=0.498 total time=  40.9s\n",
            "[CV 2/5] END C=100, degree=5, gamma=1, kernel=linear;, score=0.522 total time=  37.9s\n",
            "[CV 3/5] END C=100, degree=5, gamma=1, kernel=linear;, score=0.491 total time=  36.7s\n",
            "[CV 4/5] END C=100, degree=5, gamma=1, kernel=linear;, score=0.469 total time=  43.1s\n",
            "[CV 5/5] END C=100, degree=5, gamma=1, kernel=linear;, score=0.474 total time=  37.1s\n",
            "[CV 1/5] END C=100, degree=5, gamma=0.1, kernel=linear;, score=0.498 total time=  42.3s\n",
            "[CV 2/5] END C=100, degree=5, gamma=0.1, kernel=linear;, score=0.522 total time=  37.9s\n",
            "[CV 3/5] END C=100, degree=5, gamma=0.1, kernel=linear;, score=0.491 total time=  38.0s\n",
            "[CV 4/5] END C=100, degree=5, gamma=0.1, kernel=linear;, score=0.469 total time=  41.3s\n",
            "[CV 5/5] END C=100, degree=5, gamma=0.1, kernel=linear;, score=0.474 total time=  37.2s\n",
            "[CV 1/5] END C=100, degree=5, gamma=0.01, kernel=linear;, score=0.498 total time=  44.3s\n",
            "[CV 2/5] END C=100, degree=5, gamma=0.01, kernel=linear;, score=0.522 total time=  40.0s\n",
            "[CV 3/5] END C=100, degree=5, gamma=0.01, kernel=linear;, score=0.491 total time=  40.3s\n",
            "[CV 4/5] END C=100, degree=5, gamma=0.01, kernel=linear;, score=0.469 total time=  42.7s\n",
            "[CV 5/5] END C=100, degree=5, gamma=0.01, kernel=linear;, score=0.474 total time=  37.0s\n",
            "[CV 1/5] END C=100, degree=5, gamma=0.001, kernel=linear;, score=0.498 total time=  42.2s\n",
            "[CV 2/5] END C=100, degree=5, gamma=0.001, kernel=linear;, score=0.522 total time=  38.4s\n",
            "[CV 3/5] END C=100, degree=5, gamma=0.001, kernel=linear;, score=0.491 total time=  37.6s\n",
            "[CV 4/5] END C=100, degree=5, gamma=0.001, kernel=linear;, score=0.469 total time=  40.3s\n",
            "[CV 5/5] END C=100, degree=5, gamma=0.001, kernel=linear;, score=0.474 total time=  36.0s\n",
            "[CV 1/5] END C=100, degree=5, gamma=0.0001, kernel=linear;, score=0.498 total time=  40.9s\n",
            "[CV 2/5] END C=100, degree=5, gamma=0.0001, kernel=linear;, score=0.522 total time=  36.7s\n",
            "[CV 3/5] END C=100, degree=5, gamma=0.0001, kernel=linear;, score=0.491 total time=  36.9s\n",
            "[CV 4/5] END C=100, degree=5, gamma=0.0001, kernel=linear;, score=0.469 total time=  39.3s\n",
            "[CV 5/5] END C=100, degree=5, gamma=0.0001, kernel=linear;, score=0.474 total time=  34.5s\n",
            "[CV 1/5] END C=100, degree=6, gamma=1, kernel=linear;, score=0.498 total time=  40.2s\n",
            "[CV 2/5] END C=100, degree=6, gamma=1, kernel=linear;, score=0.522 total time=  37.3s\n",
            "[CV 3/5] END C=100, degree=6, gamma=1, kernel=linear;, score=0.491 total time=  37.8s\n",
            "[CV 4/5] END C=100, degree=6, gamma=1, kernel=linear;, score=0.469 total time=  41.4s\n",
            "[CV 5/5] END C=100, degree=6, gamma=1, kernel=linear;, score=0.474 total time=  35.2s\n",
            "[CV 1/5] END C=100, degree=6, gamma=0.1, kernel=linear;, score=0.498 total time=  41.6s\n",
            "[CV 2/5] END C=100, degree=6, gamma=0.1, kernel=linear;, score=0.522 total time=  39.8s\n",
            "[CV 3/5] END C=100, degree=6, gamma=0.1, kernel=linear;, score=0.491 total time=  39.1s\n",
            "[CV 4/5] END C=100, degree=6, gamma=0.1, kernel=linear;, score=0.469 total time=  40.0s\n",
            "[CV 5/5] END C=100, degree=6, gamma=0.1, kernel=linear;, score=0.474 total time=  34.6s\n",
            "[CV 1/5] END C=100, degree=6, gamma=0.01, kernel=linear;, score=0.498 total time=  40.9s\n",
            "[CV 2/5] END C=100, degree=6, gamma=0.01, kernel=linear;, score=0.522 total time=  37.6s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1Gs3YM7Ix-1"
      },
      "source": [
        "# Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ONV1QT5XITX2",
        "outputId": "04ca8855-eb71-4203-da87-52f32152fd09"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gbc = GradientBoostingClassifier(n_estimators=1000, validation_fraction=0.2, n_iter_no_change=10, tol=0.01, random_state=0, verbose=0 )\n",
        "scores = cross_validate(gbc, X_train, Y_train, cv=5, return_train_score=False, n_jobs=-1)\n",
        "print(\"cv test score\",scores['test_score'].mean())\n",
        "gbc.fit(X_train, Y_train)\n",
        "'''\n",
        "y_pred = gbc.predict(X_test)\n",
        "print('accuracy %s' % accuracy_score(Y_test, y_pred))\n",
        "print(classification_report(Y_test, y_pred))\n",
        "print(confusion_matrix(Y_test, y_pred))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cv test score 0.5007070947534513\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ny_pred = gbc.predict(X_test)\\nprint('accuracy %s' % accuracy_score(Y_test, y_pred))\\nprint(classification_report(Y_test, y_pred))\\nprint(confusion_matrix(Y_test, y_pred))\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TS7EJvAtq0tC",
        "outputId": "4ac7452a-c79c-43b7-a672-cee9a7e32bce"
      },
      "source": [
        "from sklearn.model_selection import learning_curve, GridSearchCV\n",
        "\n",
        "parameters = {\n",
        "    \"vect__max_df\": (0.5, 0.75, 1.0),\n",
        "    'vect__max_features': (None, 5000, 10000, 50000),\n",
        "    \"vect__ngram_range\": ((1, 1), (1, 2)),  # unigrams or bigrams\n",
        "    # 'tfidf__use_idf': (True, False),\n",
        "    # 'tfidf__norm': ('l1', 'l2'),\n",
        "    #\"clf__max_iter\": (20,),\n",
        "    \"clf__alpha\": (1, 0.1, 0.001, 0.0001, 0.00001, 0.000001),\n",
        "    \"clf__penalty\": (\"l2\", \"elasticnet\"),\n",
        "    'clf__max_iter': (5, 10, 20, 50, 80),\n",
        "}\n",
        "\n",
        "pipeline = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', SGDClassifier())\n",
        "               ])\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X_train, Y_train)\n",
        "best_parameters = grid_search.best_estimator_.get_params()\n",
        "\n",
        "for param_name in sorted(parameters.keys()):\n",
        "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n",
            "\tclf__alpha: 0.0001\n",
            "\tclf__max_iter: 5\n",
            "\tclf__penalty: 'elasticnet'\n",
            "\tvect__max_df: 1.0\n",
            "\tvect__max_features: 50000\n",
            "\tvect__ngram_range: (1, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJY9E1q00cQR",
        "outputId": "0f71fa34-8387-4d32-9e91-4cda5bcc023e"
      },
      "source": [
        "grid_search.score(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5960088691796009"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mF7HbXPTAr7l"
      },
      "source": [
        "# DEEP LEARNING MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWzkVj_2D286"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "max_words = 10000\n",
        "max_len = 150\n",
        "tokenize = Tokenizer(num_words=max_words, char_level=False)\n",
        "tokenize.fit_on_texts(train_data['tweet_without_stopwords']) \n",
        "sequences = tokenize.texts_to_sequences(train_data['tweet_without_stopwords'])\n",
        "data = pad_sequences(sequences, maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz2ODO5h085E"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "max_words = 12000\n",
        "max_len = 150\n",
        "tokenize = Tokenizer(num_words=max_words, char_level=False)\n",
        "tokenize.fit_on_texts(train_data['tweets_wo_freq_words']) \n",
        "sequences = tokenize.texts_to_sequences(train_data['tweets_wo_freq_words'])\n",
        "data = pad_sequences(sequences, maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twhWK1wQ3ZmE"
      },
      "source": [
        "labels = tf.keras.utils.to_categorical(train_data['class'], 3, dtype=\"float32\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKKZznMrDEZ2"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(data, labels, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bayi77hFNhV_",
        "outputId": "337f5694-25fb-4e41-a256-0b0c534df2ea"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9017, 150)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Leq8MmWjNjda",
        "outputId": "c438ecd6-1a54-46d2-98cc-a262e5244757"
      },
      "source": [
        "Y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9017, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANN"
      ],
      "metadata": {
        "id": "llr_EwdVop9p"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S69i4tfZFfxk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f62736d-9863-46c7-f9f7-1f325536cfc1"
      },
      "source": [
        "# simple NN\n",
        "\n",
        "batch_size = 32\n",
        "max_len = 150\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_shape=(max_len,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "history = model.fit(X_train, Y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=20,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "254/254 [==============================] - 3s 5ms/step - loss: 65.9411 - accuracy: 0.3667 - val_loss: 1.0850 - val_accuracy: 0.4457\n",
            "Epoch 2/20\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 2.1368 - accuracy: 0.4218 - val_loss: 1.0753 - val_accuracy: 0.4457\n",
            "Epoch 3/20\n",
            "254/254 [==============================] - 1s 5ms/step - loss: 1.4305 - accuracy: 0.4267 - val_loss: 1.0711 - val_accuracy: 0.4457\n",
            "Epoch 4/20\n",
            "254/254 [==============================] - 1s 5ms/step - loss: 1.1974 - accuracy: 0.4313 - val_loss: 1.0703 - val_accuracy: 0.4457\n",
            "Epoch 5/20\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 1.2827 - accuracy: 0.4315 - val_loss: 1.0704 - val_accuracy: 0.4457\n",
            "Epoch 6/20\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 1.1448 - accuracy: 0.4330 - val_loss: 1.0705 - val_accuracy: 0.4457\n",
            "Epoch 7/20\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 1.1211 - accuracy: 0.4325 - val_loss: 1.0705 - val_accuracy: 0.4457\n",
            "Epoch 8/20\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 1.1187 - accuracy: 0.4331 - val_loss: 1.0704 - val_accuracy: 0.4457\n",
            "Epoch 9/20\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 1.0881 - accuracy: 0.4320 - val_loss: 1.0706 - val_accuracy: 0.4457\n",
            "Epoch 10/20\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 1.0891 - accuracy: 0.4327 - val_loss: 1.0704 - val_accuracy: 0.4457\n",
            "Epoch 11/20\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 1.0732 - accuracy: 0.4328 - val_loss: 1.0706 - val_accuracy: 0.4457\n",
            "Epoch 12/20\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 1.0962 - accuracy: 0.4323 - val_loss: 1.0705 - val_accuracy: 0.4457\n",
            "Epoch 13/20\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 1.0854 - accuracy: 0.4329 - val_loss: 1.0705 - val_accuracy: 0.4457\n",
            "Epoch 14/20\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 1.0864 - accuracy: 0.4328 - val_loss: 1.0705 - val_accuracy: 0.4457\n",
            "Epoch 15/20\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 1.0850 - accuracy: 0.4328 - val_loss: 1.0705 - val_accuracy: 0.4457\n",
            "Epoch 16/20\n",
            "254/254 [==============================] - 1s 5ms/step - loss: 1.0812 - accuracy: 0.4328 - val_loss: 1.0704 - val_accuracy: 0.4457\n",
            "Epoch 17/20\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 1.0890 - accuracy: 0.4331 - val_loss: 1.0704 - val_accuracy: 0.4457\n",
            "Epoch 18/20\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 1.0723 - accuracy: 0.4329 - val_loss: 1.0704 - val_accuracy: 0.4457\n",
            "Epoch 19/20\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 1.0803 - accuracy: 0.4328 - val_loss: 1.0705 - val_accuracy: 0.4457\n",
            "Epoch 20/20\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 1.0993 - accuracy: 0.4329 - val_loss: 1.0703 - val_accuracy: 0.4457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmfYrM8vC1lo",
        "outputId": "38d6af64-89be-41c3-e823-18a0940509e7"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test,\n",
        "                       batch_size=batch_size, verbose=1)\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 0s 3ms/step - loss: 1.0797 - accuracy: 0.4195\n",
            "Test accuracy: 0.41951218247413635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adN9dvPXBpq9"
      },
      "source": [
        "'''\n",
        "def tensorflow_based_model(): #Defined tensorflow_based_model function for training tenforflow based model\n",
        "    inputs = Input(name='inputs',shape=[max_len])#step1\n",
        "    layer = Embedding(2000,50,input_length=max_len)(inputs) #step2\n",
        "    layer = LSTM(64)(layer) #step3\n",
        "    layer = Dense(256,name='FC1')(layer) #step4\n",
        "    layer = Activation('relu')(layer) # step5\n",
        "    layer = Dropout(0.5)(layer) # step6\n",
        "    layer = Dense(1,name='out_layer')(layer) #step4 again but this time its giving only one output as because we need to classify the tweet as positive or negative\n",
        "    layer = Activation('sigmoid')(layer) #step5 but this time activation function is sigmoid for only one output.\n",
        "    model = Model(inputs=inputs,outputs=layer) #here we are getting the final output value in the model for classification\n",
        "    return model #function returning the value when we call it\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BiDirectional LSTM"
      ],
      "metadata": {
        "id": "Am35vWmdovIL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBeLZZW8iqgY",
        "outputId": "d723d04e-e28f-4672-be85-1afc20e8f4f2"
      },
      "source": [
        "#BiDirectional LSTM\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "max_len = 150\n",
        "model = Sequential()\n",
        "model.add(Embedding(3000, 128, input_length=max_len))\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n",
        "mcp_save = ModelCheckpoint('BiLstm.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=2, epsilon=1e-4, mode='min')\n",
        "callbacks=[earlyStopping,reduce_lr_loss,mcp_save]\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_data = (X_test, Y_test), callbacks = callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "Epoch 1/100\n",
            "282/282 [==============================] - 25s 77ms/step - loss: 0.5936 - accuracy: 0.4952 - val_loss: 0.5516 - val_accuracy: 0.5761 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "282/282 [==============================] - 21s 74ms/step - loss: 0.5087 - accuracy: 0.6234 - val_loss: 0.5333 - val_accuracy: 0.5849 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "282/282 [==============================] - 21s 74ms/step - loss: 0.4488 - accuracy: 0.6871 - val_loss: 0.5520 - val_accuracy: 0.5765 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "282/282 [==============================] - 21s 74ms/step - loss: 0.4082 - accuracy: 0.7261 - val_loss: 0.5772 - val_accuracy: 0.5778 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "282/282 [==============================] - 21s 73ms/step - loss: 0.3745 - accuracy: 0.7555 - val_loss: 0.5978 - val_accuracy: 0.5685 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "282/282 [==============================] - 21s 73ms/step - loss: 0.3359 - accuracy: 0.7847 - val_loss: 0.6575 - val_accuracy: 0.5623 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "282/282 [==============================] - 21s 74ms/step - loss: 0.2983 - accuracy: 0.8098 - val_loss: 0.7511 - val_accuracy: 0.5525 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "282/282 [==============================] - 21s 73ms/step - loss: 0.2678 - accuracy: 0.8330 - val_loss: 0.8256 - val_accuracy: 0.5521 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "282/282 [==============================] - ETA: 0s - loss: 0.2411 - accuracy: 0.8504\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "282/282 [==============================] - 21s 73ms/step - loss: 0.2411 - accuracy: 0.8504 - val_loss: 0.8569 - val_accuracy: 0.5477 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "282/282 [==============================] - 21s 73ms/step - loss: 0.1898 - accuracy: 0.8884 - val_loss: 0.9289 - val_accuracy: 0.5557 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "282/282 [==============================] - 21s 73ms/step - loss: 0.1751 - accuracy: 0.8952 - val_loss: 0.9731 - val_accuracy: 0.5543 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "282/282 [==============================] - 21s 73ms/step - loss: 0.1681 - accuracy: 0.9001 - val_loss: 1.0058 - val_accuracy: 0.5561 - lr: 1.0000e-04\n",
            "Epoch 00012: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0c092f3790>"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb5LylAwD3Ag",
        "outputId": "605f9126-ed1e-47cc-ad07-99d1793c47a2"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test,\n",
        "                       batch_size=batch_size, verbose=1)\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 2s 23ms/step - loss: 1.0058 - accuracy: 0.5561\n",
            "Test accuracy: 0.5560975670814514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tuQ8XISDoOl"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('my_best_model.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoY-qtMakH3y"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkOdgvL_vRSe"
      },
      "source": [
        "# Transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME7oGb_mvQSl"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "embed = hub.KerasLayer(module_url, trainable=False, name='USE_embedding')\n",
        "def build_model(embed):\n",
        "    model = Sequential([\n",
        "        Input(shape=(max_len,), dtype=tf.string),\n",
        "        embed,\n",
        "        Dense(1024, activation='elu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(512, activation='elu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.35),\n",
        "        Dense(256, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.1),\n",
        "        Dense(3, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    optimizer = tf.keras.optimizers.Adam(lr = 0.001)\n",
        "    model.compile(optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "    \n",
        "model = build_model(embed)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQ75IiXrvtst"
      },
      "source": [
        "history = model.fit(\n",
        "    X_train, Y_train,\n",
        "    validation_data=(X_test,Y_test),\n",
        "    epochs=35,\n",
        "    callbacks=[earlyStopping,reduce_lr_loss,mcp_save],\n",
        "    batch_size= 32 \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BIoJudh7QwZ"
      },
      "source": [
        "# TCN\n",
        "\n",
        "def tcn_model(kernel_size = 3, activation='relu', input_dim = None, \n",
        "                   output_dim=300, max_length = None, emb_matrix = None):\n",
        "    \n",
        "    inp = Input( shape=(max_length,))\n",
        "    x = Embedding(input_dim=input_dim, \n",
        "                  output_dim=output_dim, \n",
        "                  input_length=max_length,\n",
        "                  # Assign the embedding weight with word2vec embedding marix\n",
        "                  weights = [emb_matrix],\n",
        "                  # Set the weight to be not trainable (static)\n",
        "                  trainable = False)(inp)\n",
        "    \n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "    \n",
        "    x = TCN(128,dilations = [1, 2, 4], return_sequences=True, activation = activation, name = 'tcn1')(x)\n",
        "    x = TCN(64,dilations = [1, 2, 4], return_sequences=True, activation = activation, name = 'tcn2')(x)\n",
        "    \n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    \n",
        "    conc = concatenate([avg_pool, max_pool])\n",
        "    conc = Dense(16, activation=\"relu\")(conc)\n",
        "    conc = Dropout(0.1)(conc)\n",
        "    outp = Dense(3, activation=\"softmax\")(conc)    \n",
        "\n",
        "    model = Model(inputs=inp, outputs=outp)\n",
        "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZrt8Y2rAsd0"
      },
      "source": [
        "model = tcn_model(kernel_size = 3, activation='relu', input_dim = 2000, output_dim=300, max_length = 12000, emb_matrix = None)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n",
        "mcp_save = ModelCheckpoint('Transfer_model.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=2, epsilon=1e-4, mode='min')\n",
        "callbacks=[earlyStopping,reduce_lr_loss,mcp_save]\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_data = (X_test, Y_test), callbacks = callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Comparision"
      ],
      "metadata": {
        "id": "UfdZEIiG7oHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "7VEPHAxP_bzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = ['Logistic Regression', 'SGD classifier', 'Naive bayes', 'Random Forest', 'XGBoost', 'SVM', 'Gradient Boost', 'GridSearchCV', 'Feed forward network', 'Bi-directional LSTM']\n",
        "acc = [60, 53, 52, 55, 55, 55.5, 50, 59.6, 41, 55]\n",
        "plt.barh(models, acc, align='center')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "u6iZhH-l7sSO",
        "outputId": "c257639b-7f2f-4ed5-9441-e95be1e93381"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 10 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}